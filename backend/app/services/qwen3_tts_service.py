"""
Qwen3-TTS Service for VoxChina
åŸºäº Qwen3-TTS çš„è¯­éŸ³å…‹éš†æœåŠ¡
ä½œè€…ï¼šRen CBIT https://github.com/reneverland/
"""

import os
import re
import torch
import soundfile as sf
from loguru import logger
from typing import Optional, Tuple, List
import numpy as np

# é•¿æ–‡æœ¬åˆ†æ®µé˜ˆå€¼ï¼ˆå­—ç¬¦æ•°ï¼‰
MAX_TEXT_LENGTH = 500  # Qwen3-TTS å¯¹äºè¿‡é•¿æ–‡æœ¬å¯èƒ½ä¼šè¶…æ—¶ï¼Œåˆ†æ®µå¤„ç†

# Qwen3-TTS æ¨¡å‹è·¯å¾„
QWEN3_TTS_MODEL_PATH = "/www/wwwroot/voxchina/backend/models/qwen3-tts/Qwen3-TTS-12Hz-1.7B-Base"
QWEN3_TTS_TOKENIZER_PATH = "/www/wwwroot/voxchina/backend/models/qwen3-tts/Qwen3-TTS-Tokenizer-12Hz"

# å°è¯•å¯¼å…¥ qwen_tts
QWEN3_TTS_AVAILABLE = False
try:
    from qwen_tts import Qwen3TTSModel
    QWEN3_TTS_AVAILABLE = True
    logger.info("âœ… [Qwen3TTS] qwen_tts package imported successfully")
except ImportError as e:
    logger.warning(f"âš ï¸ [Qwen3TTS] qwen_tts package not available: {e}")


class Qwen3TTSService:
    """Qwen3-TTS è¯­éŸ³å…‹éš†æœåŠ¡"""
    
    def __init__(self):
        self.device = "cuda:0" if torch.cuda.is_available() else "cpu"
        self.output_dir = "static/audio"
        os.makedirs(self.output_dir, exist_ok=True)
        
        self.model = None
        self.loaded = False
        self._voice_prompts = {}  # ç¼“å­˜å·²åˆ›å»ºçš„ voice_clone_prompt
        
        logger.info(f"[Qwen3TTS] Initialized with device: {self.device}")
    
    def load_model(self):
        """åŠ è½½ Qwen3-TTS æ¨¡å‹"""
        if self.loaded:
            logger.info("[Qwen3TTS] Model already loaded, skipping")
            return True
        
        if not QWEN3_TTS_AVAILABLE:
            logger.error("[Qwen3TTS] qwen_tts package not available")
            return False
        
        try:
            logger.info(f"[Qwen3TTS] Loading model from: {QWEN3_TTS_MODEL_PATH}")
            
            # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(QWEN3_TTS_MODEL_PATH):
                logger.error(f"[Qwen3TTS] Model path not found: {QWEN3_TTS_MODEL_PATH}")
                return False
            
            # åŠ è½½æ¨¡å‹
            self.model = Qwen3TTSModel.from_pretrained(
                QWEN3_TTS_MODEL_PATH,
                device_map=self.device,
                dtype=torch.bfloat16,
            )
            
            self.loaded = True
            logger.info("âœ… [Qwen3TTS] Model loaded successfully")
            return True
            
        except Exception as e:
            logger.error(f"âŒ [Qwen3TTS] Failed to load model: {e}")
            import traceback
            logger.error(f"[Qwen3TTS] Traceback: {traceback.format_exc()}")
            return False
    
    def create_voice_prompt(self, voice_id: str, ref_audio_path: str, ref_text: str = "") -> bool:
        """
        ä¸ºæŒ‡å®šçš„å£°éŸ³åˆ›å»ºå¯å¤ç”¨çš„ voice_clone_prompt
        
        Args:
            voice_id: å£°éŸ³ID
            ref_audio_path: å‚è€ƒéŸ³é¢‘æ–‡ä»¶è·¯å¾„
            ref_text: å‚è€ƒéŸ³é¢‘çš„æ–‡æœ¬å†…å®¹ï¼ˆå¯é€‰ï¼Œä½†æä¾›ä¼šæé«˜å…‹éš†è´¨é‡ï¼‰
        
        Returns:
            æ˜¯å¦æˆåŠŸåˆ›å»º
        """
        if not self.loaded:
            if not self.load_model():
                return False
        
        try:
            logger.info(f"[Qwen3TTS] Creating voice prompt for voice_id: {voice_id}")
            logger.info(f"[Qwen3TTS] ref_audio_path: {ref_audio_path}")
            logger.info(f"[Qwen3TTS] ref_text: {ref_text[:50]}..." if ref_text else "[Qwen3TTS] ref_text: (empty)")
            
            # åˆ›å»º voice_clone_prompt
            # å¦‚æœæ²¡æœ‰æä¾› ref_textï¼Œä½¿ç”¨ x_vector_only_mode
            if ref_text:
                prompt = self.model.create_voice_clone_prompt(
                    ref_audio=ref_audio_path,
                    ref_text=ref_text,
                    x_vector_only_mode=False,
                )
            else:
                prompt = self.model.create_voice_clone_prompt(
                    ref_audio=ref_audio_path,
                    ref_text="",
                    x_vector_only_mode=True,
                )
            
            # ç¼“å­˜ prompt
            self._voice_prompts[voice_id] = prompt
            logger.info(f"âœ… [Qwen3TTS] Voice prompt created and cached for: {voice_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ [Qwen3TTS] Failed to create voice prompt: {e}")
            import traceback
            logger.error(f"[Qwen3TTS] Traceback: {traceback.format_exc()}")
            return False
    
    def _split_text_into_segments(self, text: str, max_length: int = MAX_TEXT_LENGTH) -> List[str]:
        """
        å°†é•¿æ–‡æœ¬åˆ†å‰²æˆå¤šä¸ªæ®µè½
        
        æŒ‰å¥å­è¾¹ç•Œåˆ†å‰²ï¼Œç¡®ä¿æ¯æ®µä¸è¶…è¿‡ max_length
        """
        if len(text) <= max_length:
            return [text]
        
        # æŒ‰å¥å­åˆ†å‰²ï¼ˆä¸­è‹±æ–‡æ ‡ç‚¹ï¼‰
        sentence_endings = r'[ã€‚ï¼ï¼Ÿ.!?\n]+'
        sentences = re.split(f'({sentence_endings})', text)
        
        # é‡æ–°ç»„åˆå¥å­å’Œæ ‡ç‚¹
        combined = []
        for i in range(0, len(sentences) - 1, 2):
            sentence = sentences[i]
            ending = sentences[i + 1] if i + 1 < len(sentences) else ''
            combined.append(sentence + ending)
        if len(sentences) % 2 == 1 and sentences[-1].strip():
            combined.append(sentences[-1])
        
        # åˆå¹¶æˆæ®µè½
        segments = []
        current_segment = ""
        
        for sentence in combined:
            if not sentence.strip():
                continue
            
            if len(current_segment) + len(sentence) <= max_length:
                current_segment += sentence
            else:
                if current_segment.strip():
                    segments.append(current_segment.strip())
                current_segment = sentence
        
        if current_segment.strip():
            segments.append(current_segment.strip())
        
        # å¦‚æœåˆ†å‰²åä»æœ‰è¶…é•¿æ®µè½ï¼Œå¼ºåˆ¶æŒ‰é•¿åº¦åˆ‡åˆ†
        final_segments = []
        for seg in segments:
            if len(seg) <= max_length:
                final_segments.append(seg)
            else:
                # å¼ºåˆ¶åˆ‡åˆ†
                for i in range(0, len(seg), max_length):
                    final_segments.append(seg[i:i + max_length])
        
        logger.info(f"[Qwen3TTS] Split text into {len(final_segments)} segments")
        return final_segments

    def generate_audio(
        self, 
        text: str, 
        output_filename: str, 
        voice_id: str = None,
        ref_audio_path: str = None,
        ref_text: str = "",
        language: str = "Chinese",
        speed: float = 1.0
    ) -> Optional[str]:
        """
        ä½¿ç”¨ Qwen3-TTS ç”Ÿæˆè¯­éŸ³
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            output_filename: è¾“å‡ºæ–‡ä»¶å
            voice_id: å£°éŸ³IDï¼ˆå¦‚æœå·²ç¼“å­˜ promptï¼‰
            ref_audio_path: å‚è€ƒéŸ³é¢‘è·¯å¾„ï¼ˆå¦‚æœæ²¡æœ‰ç¼“å­˜ promptï¼‰
            ref_text: å‚è€ƒéŸ³é¢‘æ–‡æœ¬
            language: è¯­è¨€ (Chinese, English, Japanese, Korean, etc.)
            speed: è¯­é€Ÿï¼ˆç›®å‰ Qwen3-TTS ä¸ç›´æ¥æ”¯æŒï¼Œä¿ç•™å‚æ•°ï¼‰
        
        Returns:
            ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å› None
        """
        if not self.loaded:
            logger.info("[Qwen3TTS] Model not loaded, loading now...")
            if not self.load_model():
                logger.error("[Qwen3TTS] Failed to load model")
                return None
        
        logger.info(f"[Qwen3TTS] ğŸ¤ Generating audio: text_length={len(text)}, voice_id={voice_id}")
        
        try:
            final_path = os.path.join(self.output_dir, output_filename)
            
            # è·å–æˆ–åˆ›å»º voice_clone_prompt
            voice_prompt = None
            
            if voice_id and voice_id in self._voice_prompts:
                # ä½¿ç”¨ç¼“å­˜çš„ prompt
                voice_prompt = self._voice_prompts[voice_id]
                logger.info(f"[Qwen3TTS] Using cached voice prompt for: {voice_id}")
            elif ref_audio_path:
                # å³æ—¶åˆ›å»º prompt
                logger.info(f"[Qwen3TTS] Creating voice prompt on-the-fly from: {ref_audio_path}")
                if ref_text:
                    voice_prompt = self.model.create_voice_clone_prompt(
                        ref_audio=ref_audio_path,
                        ref_text=ref_text,
                        x_vector_only_mode=False,
                    )
                else:
                    voice_prompt = self.model.create_voice_clone_prompt(
                        ref_audio=ref_audio_path,
                        ref_text="",
                        x_vector_only_mode=True,
                    )
                
                # å¦‚æœæœ‰ voice_idï¼Œç¼“å­˜èµ·æ¥
                if voice_id:
                    self._voice_prompts[voice_id] = voice_prompt
            
            if voice_prompt is None:
                logger.error("[Qwen3TTS] No voice prompt available (no voice_id or ref_audio_path)")
                return None
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†æ®µå¤„ç†
            if len(text) > MAX_TEXT_LENGTH:
                logger.info(f"[Qwen3TTS] Long text detected ({len(text)} chars), using segmented generation")
                return self._generate_audio_segmented(
                    text=text,
                    output_filename=output_filename,
                    voice_prompt=voice_prompt,
                    language=language,
                    final_path=final_path
                )
            
            # çŸ­æ–‡æœ¬ï¼šç›´æ¥ç”Ÿæˆ
            logger.info(f"[Qwen3TTS] Generating voice clone with language: {language}")
            wavs, sr = self.model.generate_voice_clone(
                text=text,
                language=language,
                voice_clone_prompt=voice_prompt,
            )
            
            # ä¿å­˜éŸ³é¢‘
            sf.write(final_path, wavs[0], sr)
            logger.info(f"âœ… [Qwen3TTS] Audio saved to: {final_path}")
            
            return final_path
            
        except Exception as e:
            logger.error(f"âŒ [Qwen3TTS] Audio generation failed: {e}")
            import traceback
            logger.error(f"[Qwen3TTS] Traceback: {traceback.format_exc()}")
            return None
    
    def _generate_audio_segmented(
        self,
        text: str,
        output_filename: str,
        voice_prompt,
        language: str,
        final_path: str
    ) -> Optional[str]:
        """
        åˆ†æ®µç”Ÿæˆé•¿æ–‡æœ¬çš„éŸ³é¢‘ï¼Œç„¶ååˆå¹¶
        """
        try:
            segments = self._split_text_into_segments(text)
            logger.info(f"[Qwen3TTS] Processing {len(segments)} segments...")
            
            all_audio = []
            sr = None
            
            for i, segment in enumerate(segments):
                logger.info(f"[Qwen3TTS] Generating segment {i+1}/{len(segments)} ({len(segment)} chars)")
                
                try:
                    wavs, sample_rate = self.model.generate_voice_clone(
                        text=segment,
                        language=language,
                        voice_clone_prompt=voice_prompt,
                    )
                    
                    if sr is None:
                        sr = sample_rate
                    
                    all_audio.append(wavs[0])
                    logger.info(f"[Qwen3TTS] âœ… Segment {i+1} completed")
                    
                except Exception as seg_error:
                    logger.error(f"[Qwen3TTS] âŒ Segment {i+1} failed: {seg_error}")
                    # ç»§ç»­å¤„ç†å…¶ä»–æ®µè½
                    continue
            
            if not all_audio:
                logger.error("[Qwen3TTS] No audio segments generated successfully")
                return None
            
            # åˆå¹¶æ‰€æœ‰éŸ³é¢‘æ®µè½
            logger.info(f"[Qwen3TTS] Concatenating {len(all_audio)} audio segments...")
            
            # åœ¨æ®µè½ä¹‹é—´æ·»åŠ çŸ­æš‚åœé¡¿ï¼ˆ0.3ç§’é™éŸ³ï¼‰
            silence_duration = int(sr * 0.3)
            silence = np.zeros(silence_duration, dtype=np.float32)
            
            combined_audio = []
            for i, audio in enumerate(all_audio):
                combined_audio.append(audio)
                if i < len(all_audio) - 1:
                    combined_audio.append(silence)
            
            final_audio = np.concatenate(combined_audio)
            
            # ä¿å­˜åˆå¹¶åçš„éŸ³é¢‘
            sf.write(final_path, final_audio, sr)
            logger.info(f"âœ… [Qwen3TTS] Segmented audio saved to: {final_path} (total {len(final_audio)/sr:.1f}s)")
            
            return final_path
            
        except Exception as e:
            logger.error(f"âŒ [Qwen3TTS] Segmented generation failed: {e}")
            import traceback
            logger.error(f"[Qwen3TTS] Traceback: {traceback.format_exc()}")
            return None
    
    def clear_voice_prompt(self, voice_id: str):
        """æ¸…é™¤æŒ‡å®šå£°éŸ³çš„ç¼“å­˜ prompt"""
        if voice_id in self._voice_prompts:
            del self._voice_prompts[voice_id]
            logger.info(f"[Qwen3TTS] Cleared voice prompt cache for: {voice_id}")
    
    def is_available(self) -> bool:
        """æ£€æŸ¥ Qwen3-TTS æ˜¯å¦å¯ç”¨"""
        return QWEN3_TTS_AVAILABLE and os.path.exists(QWEN3_TTS_MODEL_PATH)


# å…¨å±€å•ä¾‹
qwen3_tts_service = Qwen3TTSService()
