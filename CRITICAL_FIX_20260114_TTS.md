# ğŸ”¥ å…³é”®ä¿®å¤ï¼šTTSéŸ³é¢‘ç”Ÿæˆå¤±è´¥é—®é¢˜

**æ—¥æœŸ**: 2026-01-14 23:52  
**é—®é¢˜**: éŸ³é¢‘ç”Ÿæˆä¸€ç›´è¿”å› 500 é”™è¯¯  
**æ ¹æœ¬åŸå› **: MeloTTS åº“ä¸­çš„ tokenizer æœªæ­£ç¡®åˆå§‹åŒ–

---

## ğŸ› é—®é¢˜è¯¦æƒ…

### é”™è¯¯ä¿¡æ¯
```
Generation failed: 500 - {"detail":"Audio generation failed. Please check if TTS models are properly loaded. Check server logs for details."}
```

### æ ¹æœ¬åŸå› 
åœ¨ `melotts_repo/melo/text/chinese_mix.py` æ–‡ä»¶ä¸­ï¼š
- ç¬¬101è¡Œå®šä¹‰äº† `tokenizer = None` ï¼ˆæ‡’åŠ è½½ï¼‰
- ç¬¬103è¡Œå®šä¹‰äº† `_get_tokenizer()` å‡½æ•°ç”¨äºæ‡’åŠ è½½
- ç¬¬138è¡Œæ­£ç¡®ä½¿ç”¨äº† `tok = _get_tokenizer()`
- **ä½†ç¬¬230è¡Œç›´æ¥ä½¿ç”¨äº† `tokenizer.tokenize(text)`ï¼Œå¯¼è‡´ AttributeError**

### é”™è¯¯å †æ ˆ
```python
AttributeError: 'NoneType' object has no attribute 'tokenize'
  File "/www/wwwroot/voxchina/backend/melotts_repo/melo/text/chinese_mix.py", line 230, in _g2p_v2
    tokenized_en = tokenizer.tokenize(text)
                   ^^^^^^^^^^^^^^^^^^
```

---

## âœ… ä¿®å¤æ–¹æ¡ˆ

### ä¿®æ”¹æ–‡ä»¶
`backend/melotts_repo/melo/text/chinese_mix.py`

### ä¿®æ”¹å†…å®¹
**ç¬¬227-231è¡Œï¼Œä¿®æ”¹å‰ï¼š**
```python
for text in texts:
    if re.match('[a-zA-Z\s]+', text):
        # english
        tokenized_en = tokenizer.tokenize(text)  # âŒ é”™è¯¯ï¼štokenizer æ˜¯ None
        phones_en, tones_en, word2ph_en = g2p_en(text=None, pad_start_end=False, tokenized=tokenized_en)
```

**ä¿®æ”¹åï¼š**
```python
for text in texts:
    if re.match('[a-zA-Z\s]+', text):
        # english
        tok = _get_tokenizer()  # âœ… æ­£ç¡®ï¼šè°ƒç”¨æ‡’åŠ è½½å‡½æ•°
        tokenized_en = tok.tokenize(text)
        phones_en, tones_en, word2ph_en = g2p_en(text=None, pad_start_end=False, tokenized=tokenized_en)
```

---

## ğŸ§ª æµ‹è¯•éªŒè¯

### æµ‹è¯•1ï¼šç›´æ¥è°ƒç”¨TTSæœåŠ¡
```bash
cd /www/wwwroot/voxchina/backend
python3 -c "
from app.services.tts_service import tts_service
result = tts_service.generate_audio('è¿™æ˜¯æµ‹è¯•æ–‡æœ¬', 'test.wav')
print(f'Result: {result}')
"
```

**ç»“æœ**ï¼š
```
âœ… Result: static/audio/test.wav
File exists: True
File size: 742362 bytes
```

### æµ‹è¯•2ï¼šAPIè°ƒç”¨
```bash
curl -X POST "http://localhost:8300/api/v1/voices/preview" \
  -H "Content-Type: application/json" \
  -d '{"voice_id": "", "text": "è¿™æ˜¯æµ‹è¯•æ–‡æœ¬", "language": "zh"}'
```

**ç»“æœ**ï¼š
```json
{"audio_url":"/static/audio/preview_default_717c44f7-e506-45a2-9010-f4ece1283f17.wav"}
```

âœ… **ä¿®å¤æˆåŠŸï¼**

---

## ğŸ“ é‡è¦è¯´æ˜

### 1. ä¸ºä»€ä¹ˆä¹‹å‰çŸ­æ–‡æœ¬èƒ½å·¥ä½œï¼Ÿ
çŸ­æ–‡æœ¬ï¼ˆå¦‚"æµ‹è¯•"ï¼‰å¯èƒ½ä¸ä¼šè§¦å‘è‹±æ–‡tokenizerçš„ä»£ç è·¯å¾„ï¼Œå› æ­¤ä¸ä¼šé‡åˆ°è¿™ä¸ªbugã€‚åªæœ‰å½“æ–‡æœ¬è¾ƒé•¿æˆ–åŒ…å«ç‰¹å®šæ¨¡å¼æ—¶ï¼Œæ‰ä¼šè¿›å…¥ç¬¬230è¡Œçš„ä»£ç ã€‚

### 2. åç«¯æ˜¯å¦éœ€è¦é‡å¯ï¼Ÿ
**æ˜¯çš„**ï¼Œä¿®æ”¹Pythonä»£ç åå¿…é¡»é‡å¯åç«¯æœåŠ¡ã€‚åç«¯è¿›ç¨‹ä¼šåœ¨å¯åŠ¨æ—¶åŠ è½½ä»£ç ï¼Œä¿®æ”¹åä¸ä¼šè‡ªåŠ¨ç”Ÿæ•ˆã€‚

### 3. å¦‚ä½•ç¡®è®¤ä¿®å¤ç”Ÿæ•ˆï¼Ÿ
- æ£€æŸ¥åç«¯è¿›ç¨‹çš„å¯åŠ¨æ—¶é—´ï¼ˆåº”è¯¥åœ¨ä¿®å¤ä¹‹åï¼‰
- æµ‹è¯•è¾ƒé•¿çš„æ–‡æœ¬éŸ³é¢‘ç”Ÿæˆ
- æŸ¥çœ‹åç«¯æ—¥å¿—ï¼Œåº”è¯¥çœ‹åˆ° `[TTS] âœ… Audio generation complete`

---

## ğŸš€ éƒ¨ç½²æ­¥éª¤

### è‡ªåŠ¨é‡å¯ï¼ˆæ¨èï¼‰
åç«¯ä½¿ç”¨çš„æ˜¯ uvicornï¼Œä¼šè‡ªåŠ¨æ£€æµ‹ä»£ç å˜åŒ–å¹¶é‡æ–°åŠ è½½ã€‚å¦‚æœä½¿ç”¨äº† `--reload` å‚æ•°ï¼Œä¿®æ”¹ä¼šè‡ªåŠ¨ç”Ÿæ•ˆã€‚

### æ‰‹åŠ¨é‡å¯
å¦‚æœè‡ªåŠ¨é‡å¯æœªç”Ÿæ•ˆï¼š
```bash
# æŸ¥æ‰¾è¿›ç¨‹
ps aux | grep "uvicorn.*8300"

# æ€æ‰è¿›ç¨‹ï¼ˆéœ€è¦ç›¸åº”æƒé™ï¼‰
sudo kill -9 <PID>

# é‡æ–°å¯åŠ¨
cd /www/wwwroot/voxchina/backend
sudo -u www bash -c "source venv/bin/activate && nohup python3 -m uvicorn main:app --host 0.0.0.0 --port 8300 --workers 1 > /dev/null 2>&1 &"
```

---

## ğŸ“Š å½±å“èŒƒå›´

### å—å½±å“çš„åŠŸèƒ½
- âœ… Academic Extract éŸ³é¢‘ç”Ÿæˆ
- âœ… Voice Preview åŠŸèƒ½
- âœ… æ‰€æœ‰ä½¿ç”¨ TTS æœåŠ¡çš„åŠŸèƒ½

### ä¸å—å½±å“çš„åŠŸèƒ½
- âœ… æ–‡ç« æå–
- âœ… æ‘˜è¦ç”Ÿæˆ
- âœ… çŸ¥è¯†åº“ä¿å­˜
- âœ… å†å²è®°å½•æŸ¥çœ‹

---

## ğŸ”— ç›¸å…³ä¿®å¤

æœ¬æ¬¡ä¿®å¤æ˜¯åœ¨ä¹‹å‰ä¿®å¤çš„åŸºç¡€ä¸Šè¿›è¡Œçš„ï¼š
1. **ä¹‹å‰çš„ä¿®å¤** (`FIXES_20260114.md`)ï¼š
   - æ”¹è¿›äº† TTS é”™è¯¯å¤„ç†å’Œæ—¥å¿—
   - ä¿®å¤äº†å†å²è®°å½•ä¸æ˜¾ç¤ºçš„é—®é¢˜
   
2. **æœ¬æ¬¡ä¿®å¤** (æœ¬æ–‡æ¡£)ï¼š
   - ä¿®å¤äº† MeloTTS tokenizer çš„ bug
   - è¿™æ˜¯å¯¼è‡´éŸ³é¢‘ç”Ÿæˆå¤±è´¥çš„**çœŸæ­£åŸå› **

---

## âœ¨ æ€»ç»“

è¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„**æ‡’åŠ è½½æœªæ­£ç¡®å®ç°**çš„bugï¼š
- ä»£ç ä¸­å®šä¹‰äº†æ‡’åŠ è½½æœºåˆ¶ï¼ˆ`_get_tokenizer()`ï¼‰
- ä½†åœ¨æŸå¤„å¿˜è®°è°ƒç”¨æ‡’åŠ è½½å‡½æ•°ï¼Œç›´æ¥ä½¿ç”¨äº†æœªåˆå§‹åŒ–çš„å˜é‡
- å¯¼è‡´ `NoneType` é”™è¯¯

**ä¿®å¤éå¸¸ç®€å•**ï¼šå°† `tokenizer.tokenize()` æ”¹ä¸º `_get_tokenizer().tokenize()`

---

**ä¿®å¤å®Œæˆæ—¶é—´**: 2026-01-14 23:52  
**ä¿®å¤äºº**: AI Assistant  
**ä½œè€…**: Ren CBIT https://github.com/reneverland/
